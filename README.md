# Data Science portfolio - Luigi Carlucci
This repository contains my Data Science portfolio, including a collection of statistics, machine learning and deep learning projects. The repository also report a list of my skills and certificates related to Data Science.

---

## Projects

<img align="left" width="240" height="160" src="https://github.com/lgucrl/deep-learning-email-classification/blob/main/images/thumbnail_email_classification.jpg">

**[Machine / Deep Learning classification and NLP analysis of emails](https://github.com/lgucrl/deep-learning-email-classification/)**  
This project builds an end-to-end pipeline in Python to **classify emails as SPAM vs. HAM (non-spam)** and then perform detailed **NLP analyses** on the resulting groups. In addition to supervised classification, it explores the **main topics** of SPAM emails, the **differences/similarities** of SPAM topics, and the **organizations mentioned** in non-spam messages.

#

<img align="left" width="240" height="160" src="https://github.com/lgucrl/deep-learning-toxic-comments-classification/blob/main/images/thumbnail_comments_toxicity.png"> 

**[Deep Learning multi-label classification of online toxic comments](https://github.com/lgucrl/deep-learning-toxic-comments-classification/)**  
This deep learning project builds a detection and classification system for **toxic comments** on social platforms: given an online comment, the model predicts whether it contains one or more types of toxicity. The classifier is implemented in **Python** using **TensorFlow/Keras** and outputs a **6-dimensional vector of binary labels** (one per toxicity category).

#

<img align="left" width="240" height="160" src="https://github.com/lgucrl/machine-learning-wikipedia-classification/blob/main/images/thumbnail_wikipedia_classification.jpg"> 

**[Machine Learning multi-class classification of Wikipedia articles](https://github.com/lgucrl/machine-learning-wikipedia-classification)**  
This repository contains an end-to-end **big data / NLP** pipeline with the goal of exploring English Wikipedia content and building an **automatic multi-class text classifier** able to assign each article to one of **15 thematic categories** (e.g., *Culture, Economics, Medicine, Technology, Politics, Science*) using **PySpark's Machine Learning Library (MLlib)**.

#

<img align="left" width="240" height="160" src="https://github.com/lgucrl/machine-learning-face-detection/blob/main/images/thumbnail_face_detection.png"> 

**[Machine Learning face detection](https://github.com/lgucrl/machine-learning-face-detection)**  
This project implements a **lightweight face detection pipeline** in Python aimed at running with **limited computing capacity** by combining classic computer vision methods with a fast, well-established machine learning model. Instead of deep neural networks, the project uses **Histogram of Oriented Gradients (HOG)** features and a **Support Vector Classifier (SVC)** to distinguish *face* vs *non-face* image patches. For detection in full-size images, the trained classifier is applied using a **sliding-window** approach and refined with **Non-Maximum Suppression (NMS)** to produce final bounding boxes.

#

<img align="left" width="240" height="160" src="https://github.com/lgucrl/machine-learning-creditworthiness-estimation/blob/main/images/thumbnail_creditworthiness_estimation.jpg"> 

**[Machine Learning estimation of creditworthiness](https://github.com/lgucrl/machine-learning-creditworthiness-estimation/)**  
This repository contains an end-to-end machine learning project in Python to estimate a bank customerâ€™s **creditworthiness** and support decisions on **credit card issuance**. The goal is to build a model that predicts a binary TARGET where 1 = high creditworthiness (consistent installment payments) and 0 = otherwise, using anonymized customer profile data. The project addresses different  ML challenges, such as handling of mixed data types, class-imbalance strategies and evaluation with metrics that reflect real-world trade-offs. 

#

<img align="left" width="240" height="160" src="https://github.com/lgucrl/machine-learning-cross-selling-prediction/blob/main/images/thumbnail_insurance_prediction.jpg"> 

**[Machine Learning prediction of insurance cross-selling](https://github.com/lgucrl/machine-learning-cross-selling-prediction)**  
This project builds a supervised **binary classification** model in Python that helps an insurance company identify **cross-selling opportunities**: among existing customers, who is most likely to be interested in purchasing an additional **vehicle insurance** policy. The work follows an end-to-end Machine Learning pipeline (EDA, preprocessing, imbalance handling, model training, evaluation) and compares multiple algorithms and thresholds to balance decision strategies like identifying as many interested customers as possible (high recall) while controlling false positives (precision).

#

**[Statistical Inference Analysis to predict newborn weight](https://github.com/lgucrl/newborn-statistical-inference-analysis)**  
This repository contains an **inferential statistics** project in R with the goal of building, validating, and interpreting a statistical model capable of **predicting newborn weight** from collected clinical variables, such as maternal, pregnancy, and newborn measurements. The analysis combines classical hypothesis testing with multiple linear regression, model selection, diagnostics, and scenario-based prediction.

#

**[Exploratory Data Analysis of the Texas Real Estate Market](https://github.com/lgucrl/real-estate-exploratory-data-analysis)**  
This project carries out an **exploratory data analysis (EDA)** of the Texas residential real estate market using R (including **dplyr**, **ggplot2**, and **moments** libraries). The goal is to apply descriptive statistics and data-visualization techniques to understand how sales activity and prices evolve across cities, months, and years.

---
